# Guia de Execu√ß√£o em Lote - Pipeline Hist√≥rico Pr√©-Natal

## üìã Vis√£o Geral

Este guia descreve como usar o script `executar_pipeline_datas_customizadas.sql` para processar m√∫ltiplas datas de uma vez, materializando apenas a tabela final `linha_tempo_historico_acumulado`.

---

## üéØ Objetivo

Executar o pipeline completo (procedimentos 1-6) para uma lista espec√≠fica de datas fornecida pelo usu√°rio, acumulando apenas os resultados da tabela 6 (linha do tempo) em uma tabela permanente.

### Por que apenas tabela 6?

- **Economia de espa√ßo**: Tabelas 1-5 s√£o intermedi√°rias e podem ser recriadas a qualquer momento
- **An√°lise temporal**: Tabela 6 cont√©m todos os indicadores agregados necess√°rios para an√°lises hist√≥ricas
- **Performance**: Reduz significativamente o espa√ßo de armazenamento necess√°rio

---

## üöÄ Como Usar

### Passo 1: Editar Lista de Datas

Abra o arquivo `executar_pipeline_datas_customizadas.sql` e localize a se√ß√£o **CONFIGURA√á√ÉO USU√ÅRIO**:

```sql
-- Lista de datas para processar (formato: 'YYYY-MM-DD')
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-01-31'),
    DATE('2024-02-29'),
    DATE('2024-03-31'),
    -- Adicione suas datas aqui
];
```

#### Exemplos de Configura√ß√£o

**Exemplo 1: √öltimos dias de cada m√™s de 2024**
```sql
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-01-31'),
    DATE('2024-02-29'),
    DATE('2024-03-31'),
    DATE('2024-04-30'),
    DATE('2024-05-31'),
    DATE('2024-06-30'),
    DATE('2024-07-31'),
    DATE('2024-08-31'),
    DATE('2024-09-30'),
    DATE('2024-10-31'),
    DATE('2024-11-30'),
    DATE('2024-12-31')
];
```

**Exemplo 2: Datas espec√≠ficas trimestrais**
```sql
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-03-31'),  -- Fim Q1
    DATE('2024-06-30'),  -- Fim Q2
    DATE('2024-09-30'),  -- Fim Q3
    DATE('2024-12-31')   -- Fim Q4
];
```

**Exemplo 3: Uma √∫nica data para teste**
```sql
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-10-31')
];
```

### Passo 2: Executar no BigQuery

1. Abra o BigQuery Console
2. Copie TODO o conte√∫do do arquivo `executar_pipeline_datas_customizadas.sql`
3. Cole no editor de queries
4. Clique em **Run** ou pressione `Ctrl+Enter`
5. Aguarde a conclus√£o (pode levar v√°rios minutos dependendo do n√∫mero de datas)

### Passo 3: Monitorar Progresso

O script exibe logs detalhados durante a execu√ß√£o:

```
========================================
ETAPA 1: Criando/Verificando Tabela Acumulativa
========================================
‚úÖ Tabela acumulativa criada/verificada com sucesso

========================================
ETAPA 2: Processando Datas Individualmente
Total de datas a processar: 12
========================================

----------------------------------------
üìÖ Processando data 1 de 12: 2024-01-31
----------------------------------------
  ‚è≥ [1/6] Executando proced_1_gestacoes_historico...
  ‚úÖ [1/6] Procedimento 1 conclu√≠do
  ‚è≥ [2/6] Executando proced_2_atd_prenatal_aps_historico...
  ‚úÖ [2/6] Procedimento 2 conclu√≠do
  ...
  ‚úÖ Data 2024-01-31 processada com sucesso!
```

---

## üìä Estrutura do Script

### Etapa 1: Cria√ß√£o da Tabela Acumulativa

O script cria automaticamente (se n√£o existir) a tabela `linha_tempo_historico_acumulado` com:

- **Particionamento**: Por `data_snapshot` (obrigat√≥rio usar filtro de data nas queries)
- **Clustering**: Por `id_paciente` e `fase_atual` (otimiza queries por paciente/fase)
- **Schema completo**: Todos os campos da linha do tempo hist√≥rica

### Etapa 2: Processamento de Cada Data

Para cada data na lista:

1. **Executa procedimentos 1-6 sequencialmente**
   - Procedimento 1: Gesta√ß√µes
   - Procedimento 2: Atendimentos Pr√©-Natal
   - Procedimento 3: Visitas ACS
   - Procedimento 4: Consultas Emergenciais
   - Procedimento 5: Encaminhamentos SISREG
   - Procedimento 6: Linha do Tempo (agrega√ß√£o)

2. **Materializa apenas tabela 6**
   - INSERT na tabela acumulativa
   - Conta registros inseridos
   - Log de confirma√ß√£o

3. **Tratamento de erros**
   - Se um procedimento falhar, pula para pr√≥xima data
   - Log detalhado do erro
   - Continua processamento das demais datas

### Etapa 3: Relat√≥rio Final

Ao final, exibe:

- Total de datas processadas
- Total de registros acumulados
- Resumo por data (gesta√ß√µes ativas, hipertens√£o, diabetes, etc.)
- Estat√≠sticas gerais da tabela acumulativa

---

## ‚è±Ô∏è Estimativa de Tempo

| N√∫mero de Datas | Tempo Estimado |
|-----------------|----------------|
| 1 data | 5-10 minutos |
| 4 datas (trimestral) | 20-40 minutos |
| 12 datas (mensal) | 1-2 horas |
| 24 datas (quinzenal) | 2-4 horas |

**Fatores que afetam performance**:
- Volume de dados nas tabelas fonte
- Hor√°rio de execu√ß√£o (off-peak √© mais r√°pido)
- Capacidade de slots dispon√≠veis no projeto BigQuery

---

## üîç Valida√ß√£o P√≥s-Execu√ß√£o

### Query 1: Verificar Snapshots Criados

```sql
SELECT
    data_snapshot,
    COUNT(*) AS total_gestacoes,
    COUNT(DISTINCT id_paciente) AS total_pacientes
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
GROUP BY data_snapshot
ORDER BY data_snapshot;
```

### Query 2: Comparar Evolu√ß√£o Temporal

```sql
SELECT
    data_snapshot,
    COUNTIF(fase_atual = 'Gesta√ß√£o') AS gestacoes_ativas,
    COUNTIF(total_consultas_prenatal >= 6) AS adequacao_6_consultas,
    ROUND(100.0 * COUNTIF(total_consultas_prenatal >= 6) / NULLIF(COUNTIF(fase_atual = 'Gesta√ß√£o'), 0), 2) AS perc_adequacao
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
GROUP BY data_snapshot
ORDER BY data_snapshot;
```

### Query 3: Verificar Integridade

```sql
-- Verificar se h√° duplicatas
SELECT
    data_snapshot,
    id_gestacao,
    COUNT(*) AS vezes_aparece
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
GROUP BY data_snapshot, id_gestacao
HAVING COUNT(*) > 1;

-- Resultado esperado: 0 linhas (sem duplicatas)
```

---

## ‚ö†Ô∏è Troubleshooting

### Problema: "Procedure not found"

**Causa**: Um ou mais procedimentos n√£o foram criados no BigQuery.

**Solu√ß√£o**:
```bash
# Criar todos os procedimentos primeiro
bq query --use_legacy_sql=false < "gestante_historico.sql"
bq query --use_legacy_sql=false < "2_atd_prenatal_aps_historico.sql"
bq query --use_legacy_sql=false < "3_visitas_acs_gestacao_historico.sql"
bq query --use_legacy_sql=false < "4_consultas_emergenciais_historico.sql"
bq query --use_legacy_sql=false < "5_encaminhamentos_historico.sql"
bq query --use_legacy_sql=false < "6_linha_tempo_historico.sql"
```

### Problema: Script interrompido no meio

**Causa**: Timeout do BigQuery ou perda de conex√£o.

**Solu√ß√£o**: O script tem tratamento de erros. Voc√™ pode:
1. Verificar quais datas foram processadas:
```sql
SELECT DISTINCT data_snapshot
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
ORDER BY data_snapshot;
```

2. Editar o array `datas_processar` removendo datas j√° processadas
3. Re-executar o script apenas com datas pendentes

### Problema: Erro "Partition filter required"

**Causa**: Query na tabela acumulativa sem filtro de `data_snapshot`.

**Solu√ß√£o**: Sempre incluir WHERE com data_snapshot:
```sql
-- ‚ùå ERRADO
SELECT * FROM linha_tempo_historico_acumulado;

-- ‚úÖ CORRETO
SELECT * FROM linha_tempo_historico_acumulado
WHERE data_snapshot = DATE('2024-10-31');

-- ‚úÖ CORRETO - m√∫ltiplas datas
SELECT * FROM linha_tempo_historico_acumulado
WHERE data_snapshot BETWEEN DATE('2024-01-31') AND DATE('2024-12-31');
```

### Problema: Registros duplicados

**Causa**: Script executado duas vezes para mesma data sem limpeza.

**Solu√ß√£o**: Limpar duplicatas antes de nova execu√ß√£o:
```sql
-- Deletar dados de data espec√≠fica antes de reprocessar
DELETE FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
WHERE data_snapshot = DATE('2024-10-31');
```

---

## üéØ Casos de Uso

### Caso 1: Build Hist√≥rico Inicial

**Objetivo**: Criar s√©rie hist√≥rica completa de 2024

```sql
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-01-31'), DATE('2024-02-29'), DATE('2024-03-31'),
    DATE('2024-04-30'), DATE('2024-05-31'), DATE('2024-06-30'),
    DATE('2024-07-31'), DATE('2024-08-31'), DATE('2024-09-30'),
    DATE('2024-10-31'), DATE('2024-11-30'), DATE('2024-12-31')
];
```

### Caso 2: Atualiza√ß√£o Mensal

**Objetivo**: Adicionar snapshot do m√™s atual

```sql
-- Executar todo final de m√™s
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    LAST_DAY(CURRENT_DATE())
];
```

### Caso 3: Reprocessamento de Dados

**Objetivo**: Reprocessar trimestre espec√≠fico

```sql
-- Primeiro: Limpar dados existentes
DELETE FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
WHERE data_snapshot IN (DATE('2024-07-31'), DATE('2024-08-31'), DATE('2024-09-30'));

-- Depois: Processar novamente
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-07-31'),
    DATE('2024-08-31'),
    DATE('2024-09-30')
];
```

### Caso 4: An√°lise Comparativa

**Objetivo**: Mesmo dia em meses diferentes

```sql
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-01-15'),
    DATE('2024-02-15'),
    DATE('2024-03-15'),
    DATE('2024-04-15'),
    DATE('2024-05-15'),
    DATE('2024-06-15')
];
```

---

## üìà An√°lises Poss√≠veis

Com a tabela acumulativa populada, voc√™ pode fazer an√°lises como:

### Evolu√ß√£o da Cobertura de Pr√©-Natal

```sql
SELECT
    data_snapshot,
    COUNTIF(fase_atual = 'Gesta√ß√£o') AS gestacoes_ativas,
    COUNTIF(total_consultas_prenatal >= 1) AS com_consulta,
    COUNTIF(total_consultas_prenatal >= 6) AS adequacao_6_consultas,
    ROUND(100.0 * COUNTIF(total_consultas_prenatal >= 6) / NULLIF(COUNTIF(fase_atual = 'Gesta√ß√£o'), 0), 2) AS perc_adequacao
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
GROUP BY data_snapshot
ORDER BY data_snapshot;
```

### Tend√™ncia de Condi√ß√µes Cl√≠nicas

```sql
SELECT
    data_snapshot,
    COUNTIF(fase_atual = 'Gesta√ß√£o') AS gestacoes_ativas,
    COUNTIF(hipertensao_total = 1) AS com_hipertensao,
    COUNTIF(diabetes_total = 1) AS com_diabetes,
    ROUND(100.0 * COUNTIF(hipertensao_total = 1) / NULLIF(COUNTIF(fase_atual = 'Gesta√ß√£o'), 0), 2) AS prevalencia_has,
    ROUND(100.0 * COUNTIF(diabetes_total = 1) / NULLIF(COUNTIF(fase_atual = 'Gesta√ß√£o'), 0), 2) AS prevalencia_dm
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
GROUP BY data_snapshot
ORDER BY data_snapshot;
```

### Distribui√ß√£o por √Årea Program√°tica ao Longo do Tempo

```sql
SELECT
    data_snapshot,
    area_programatica,
    COUNT(*) AS total_gestacoes,
    COUNTIF(fase_atual = 'Gesta√ß√£o') AS gestacoes_ativas,
    ROUND(AVG(total_consultas_prenatal), 2) AS media_consultas
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
WHERE area_programatica IS NOT NULL
GROUP BY data_snapshot, area_programatica
ORDER BY data_snapshot, area_programatica;
```

---

## üí° Boas Pr√°ticas

### 1. Teste com Data √önica Primeiro

Antes de processar 12 meses, teste com uma data:

```sql
DECLARE datas_processar ARRAY<DATE> DEFAULT [
    DATE('2024-10-31')  -- Data de teste
];
```

### 2. Execute em Hor√°rios de Baixo Uso

Para grandes volumes, prefira:
- Madrugada (00:00 - 06:00)
- Finais de semana
- Evite hor√°rio comercial (09:00 - 18:00)

### 3. Monitore Custos

Verifique custos estimados antes de executar:
- BigQuery Console ‚Üí Job History
- Observe "Bytes Processed" de execu√ß√µes anteriores
- Calcule custo estimado (US$ 5 por TB processado)

### 4. Fa√ßa Backup Antes de Reprocessar

```sql
-- Criar backup antes de deletar/reprocessar
CREATE TABLE `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado_backup_20241028` AS
SELECT * FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`;
```

### 5. Documente Datas Processadas

Mantenha um registro de quando cada snapshot foi gerado:

```sql
-- Query para documentar
SELECT
    data_snapshot,
    COUNT(*) AS registros,
    CURRENT_TIMESTAMP() AS data_processamento
FROM `rj-sms-sandbox.sub_pav_us.linha_tempo_historico_acumulado`
GROUP BY data_snapshot
ORDER BY data_snapshot;
```

---

## üìö Refer√™ncias

- **Script Principal**: `executar_pipeline_datas_customizadas.sql`
- **Documenta√ß√£o Completa**: `README_HISTORICO_COMPLETO.md`
- **Guia de Testes**: `README_TESTES.md`
- **Relat√≥rio de Testes**: `RELATORIO_TESTES_PROCEDIMENTOS_3_A_6.md`
- **Exemplo Manual**: `construir_historico_completo.sql`

---

## üÜò Suporte

Se encontrar problemas:

1. Verifique logs do script para identificar qual procedimento falhou
2. Consulte se√ß√£o Troubleshooting deste guia
3. Revise `README_TESTES.md` para valida√ß√µes espec√≠ficas
4. Verifique `RELATORIO_TESTES_PROCEDIMENTOS_3_A_6.md` para problemas conhecidos

---

**√öltima atualiza√ß√£o**: 2025-10-28
**Vers√£o**: 1.0
