# Pipeline Automatizado de HistÃ³rico de PrÃ©-Natal

## ğŸ“‹ VisÃ£o Geral

Sistema automatizado para construÃ§Ã£o de snapshots histÃ³ricos do acompanhamento prÃ©-natal na rede municipal de saÃºde do Rio de Janeiro. Este diretÃ³rio contÃ©m scripts e ferramentas para processar mÃºltiplas datas em lote, gerando dados histÃ³ricos para anÃ¡lise temporal e visualizaÃ§Ã£o em dashboard.

**Diferencial**: Pipeline completo com geraÃ§Ã£o automÃ¡tica de JSON para dashboard web.

## ğŸ¯ PropÃ³sito

Construir sÃ©rie temporal de indicadores de prÃ©-natal atravÃ©s de:
- âœ… ExecuÃ§Ã£o automatizada de mÃºltiplos snapshots
- âœ… ValidaÃ§Ã£o de prÃ©-requisitos (BigQuery CLI, autenticaÃ§Ã£o)
- âœ… Processamento sequencial com controle de erros
- âœ… GeraÃ§Ã£o automÃ¡tica de dados para dashboard
- âœ… RelatÃ³rios detalhados de execuÃ§Ã£o

## ğŸ“ Arquivos do Pipeline

### Scripts SQL

| Arquivo | Procedimento | SaÃ­da | FunÃ§Ã£o |
|---------|--------------|-------|--------|
| `_hist_1_gestacoes.sql` | `proced_1_gestacoes_historico` | `_gestacoes_historico` | Identifica e classifica gestaÃ§Ãµes (CIDs Z32.1, Z34%, Z35%) |
| `_hist_2_atd_prenatal_aps.sql` | `proced_2_atd_prenatal_aps_historico` | `_atendimentos_prenatal_aps_historico` | Atendimentos SOAP com medidas antropomÃ©tricas |
| `_hist_6_linha_tempo.sql` | `proced_6_linha_tempo_historico` | `_linha_tempo_historico` | AgregaÃ§Ã£o completa com todos os indicadores |

### Scripts Bash

| Arquivo | Tipo | FunÃ§Ã£o |
|---------|------|--------|
| `construir_historico.sh` | **Script principal** | Executa pipeline completo + gera JSON do dashboard |
| `exemplo_uso.sh` | Exemplos | Demonstra diferentes padrÃµes de uso |

### DocumentaÃ§Ã£o

| Arquivo | ConteÃºdo |
|---------|----------|
| `README_CONSTRUIR_HISTORICO.md` | Guia completo de uso do script automatizado |
| `README.md` | Esta documentaÃ§Ã£o (overview do pipeline) |

## ğŸ”„ Arquitetura do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENTRADA: Lista de datas (YYYY-MM-DD)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Para cada data:            â”‚
        â”‚  1. _hist_1_gestacoes.sql   â”‚ â†’ INSERT INTO _gestacoes_historico
        â”‚  2. _hist_2_atd_prenatal    â”‚ â†’ INSERT INTO _atendimentos_prenatal_aps_historico
        â”‚  3. _hist_6_linha_tempo     â”‚ â†’ INSERT INTO _linha_tempo_historico
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ApÃ³s processar todas:      â”‚
        â”‚  4. Query dashboard         â”‚ â†’ dashboard_data_completo.json
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  SAÃDA:                     â”‚
        â”‚  â€¢ Snapshots em BigQuery    â”‚
        â”‚  â€¢ JSON para dashboard      â”‚
        â”‚  â€¢ RelatÃ³rio de execuÃ§Ã£o    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos

```bash
# Verificar BigQuery CLI
bq version

# Se nÃ£o instalado:
gcloud components install bq

# Autenticar
gcloud auth login
gcloud config set project rj-sms-sandbox
```

### 2. Executar Pipeline

**OpÃ§Ã£o A: Passar datas como argumentos** (Recomendado para testes)

```bash
cd SQL_histÃ³rico
./construir_historico.sh 2024-10-01
```

**OpÃ§Ã£o B: Configurar datas no script** (Recomendado para produÃ§Ã£o)

```bash
# Editar o script
nano construir_historico.sh

# Descomentar e preencher o array DATAS_PROCESSAR (linhas 26-39)
DATAS_PROCESSAR=(
    "2024-01-01"
    "2024-02-01"
    "2024-03-01"
    # ... adicionar suas datas
)

# Executar
./construir_historico.sh
```

### 3. Visualizar Resultados

```bash
# Iniciar servidor HTTP (se nÃ£o estiver rodando)
cd ..  # Voltar para raiz do projeto
python3 -m http.server 8000

# Abrir no navegador
# http://localhost:8000/dashboard_prescricoes_v2.html
```

## ğŸ“Š Ordem de ExecuÃ§Ã£o Detalhada

### Fase 1: Processamento por Data

Para cada data especificada:

```
1. _hist_1_gestacoes.sql (1/3)
   â”œâ”€ Identifica gestaÃ§Ãµes por CIDs obstÃ©tricos
   â”œâ”€ Agrupa inÃ­cios com janela de 60 dias
   â”œâ”€ Classifica fase: GestaÃ§Ã£o/PuerpÃ©rio/Encerrada
   â””â”€ INSERT INTO _gestacoes_historico

2. _hist_2_atd_prenatal_aps.sql (2/3)
   â”œâ”€ Depende: _gestacoes_historico com data_snapshot
   â”œâ”€ Extrai atendimentos SOAP em APS
   â”œâ”€ Calcula IMC, peso inicial, ganho de peso
   â””â”€ INSERT INTO _atendimentos_prenatal_aps_historico

3. _hist_6_linha_tempo.sql (3/3)
   â”œâ”€ Depende: _gestacoes_historico + _atendimentos_prenatal_aps_historico
   â”œâ”€ Agrega condiÃ§Ãµes clÃ­nicas, medicaÃ§Ãµes, encaminhamentos
   â”œâ”€ Calcula indicadores de hipertensÃ£o, diabetes, prescriÃ§Ãµes
   â””â”€ INSERT INTO _linha_tempo_historico
```

### Fase 2: GeraÃ§Ã£o do Dashboard

ApÃ³s processar todas as datas com sucesso:

```
4. query_dashboard_completo_clean.sql
   â”œâ”€ Agrega dados de TODOS os snapshots
   â”œâ”€ Calcula indicadores percentuais
   â”œâ”€ Exporta em formato JSON
   â””â”€ Salva em: ../dashboard_data_completo.json
```

## ğŸ’¡ Casos de Uso

### 1. Snapshot Ãšnico (Teste Inicial)

```bash
# Processar apenas Ãºltima data disponÃ­vel
./construir_historico.sh 2024-10-01

# âœ… Ãštil para: Validar pipeline, testar nova data
# â±ï¸  Tempo esperado: ~1-2 minutos
```

### 2. ComparaÃ§Ã£o Antes/Depois

```bash
# Dois pontos no tempo
./construir_historico.sh 2024-07-01 2024-10-01

# âœ… Ãštil para: Avaliar impacto de intervenÃ§Ãµes
# ğŸ“Š Dashboard: Mostra evoluÃ§Ã£o entre perÃ­odos
```

### 3. SÃ©rie Mensal Completa

```bash
# Todos os meses de 2024
./construir_historico.sh \
    2024-01-01 2024-02-01 2024-03-01 \
    2024-04-01 2024-05-01 2024-06-01 \
    2024-07-01 2024-08-01 2024-09-01 \
    2024-10-01 2024-11-01 2024-12-01

# âœ… Ãštil para: AnÃ¡lise temporal completa do ano
# â±ï¸  Tempo esperado: ~12-24 minutos
# ğŸ“Š Dashboard: GrÃ¡ficos de tendÃªncia anual
```

### 4. SÃ©rie Trimestral

```bash
# Ãšltimo dia de cada trimestre
./construir_historico.sh \
    2024-03-01 2024-06-01 2024-09-01 2024-12-01

# âœ… Ãštil para: RelatÃ³rios trimestrais, reduÃ§Ã£o de processamento
# â±ï¸  Tempo esperado: ~4-8 minutos
```

### 5. SÃ©rie Semanal (MÃªs EspecÃ­fico)

```bash
# Todas as segundas de outubro/2024
./construir_historico.sh \
    2024-10-07 2024-10-14 2024-10-21 2024-10-28

# âœ… Ãštil para: AnÃ¡lise detalhada de curto prazo
# ğŸ“Š Dashboard: Granularidade semanal
```

### 6. Datas Customizadas (Eventos EspecÃ­ficos)

```bash
# Marcos temporais relevantes
./construir_historico.sh \
    2024-01-15 2024-04-22 2024-07-10 2024-10-31

# âœ… Ãštil para: Antes/depois de campanhas, mudanÃ§as de protocolo
```

## ğŸ” ValidaÃ§Ã£o de Resultados

### Verificar Snapshots no BigQuery

```sql
-- Listar snapshots processados
SELECT DISTINCT data_snapshot
FROM `rj-sms-sandbox.sub_pav_us._linha_tempo_historico`
ORDER BY data_snapshot DESC;

-- Contagem por snapshot
SELECT
    data_snapshot,
    COUNT(*) AS total_gestacoes,
    COUNTIF(fase_atual = 'GestaÃ§Ã£o') AS ativas,
    COUNTIF(fase_atual = 'PuerpÃ©rio') AS puerperio
FROM `rj-sms-sandbox.sub_pav_us._linha_tempo_historico`
GROUP BY data_snapshot
ORDER BY data_snapshot DESC;
```

### Verificar JSON do Dashboard

```bash
# Contar snapshots no JSON
cat ../dashboard_data_completo.json | python3 -m json.tool | grep -c "data_snapshot"

# Ver datas incluÃ­das
cat ../dashboard_data_completo.json | python3 -c "
import json, sys
data = json.load(sys.stdin)
for row in data:
    print(row['data_snapshot'], '-', row['total_gestantes_ativas'], 'gestantes')
"
```

### Verificar ConsistÃªncia Entre Tabelas

```sql
-- Garantir que todas as 3 tabelas tÃªm dados para mesmas datas
WITH snapshots_por_tabela AS (
    SELECT DISTINCT data_snapshot, 'gestacoes' AS tabela
    FROM `rj-sms-sandbox.sub_pav_us._gestacoes_historico`
    UNION ALL
    SELECT DISTINCT data_snapshot, 'atendimentos'
    FROM `rj-sms-sandbox.sub_pav_us._atendimentos_prenatal_aps_historico`
    UNION ALL
    SELECT DISTINCT data_snapshot, 'linha_tempo'
    FROM `rj-sms-sandbox.sub_pav_us._linha_tempo_historico`
)
SELECT
    data_snapshot,
    COUNT(DISTINCT tabela) AS tabelas_com_dados,
    STRING_AGG(tabela, ', ') AS tabelas_presentes
FROM snapshots_por_tabela
GROUP BY data_snapshot
HAVING COUNT(DISTINCT tabela) < 3  -- Alerta se faltar alguma tabela
ORDER BY data_snapshot;
```

## âš™ï¸ Funcionamento Interno

### SubstituiÃ§Ã£o DinÃ¢mica de Datas

O script usa `sed` para substituir a data em tempo de execuÃ§Ã£o:

```bash
# ConteÃºdo original do SQL
DECLARE data_referencia DATE DEFAULT DATE('2024-07-01');

# Script substitui por:
DECLARE data_referencia DATE DEFAULT DATE('2024-10-01');  # Data atual do loop

# Arquivo temporÃ¡rio criado â†’ executado â†’ deletado
```

### Controle de Erros

```bash
# Interrompe se qualquer SQL falhar
set -e

# Rastreia sucessos e falhas
for DATA in "${DATAS_PROCESSAR[@]}"; do
    if executar_sql "1_gestacoes" && \
       executar_sql "2_atendimentos" && \
       executar_sql "6_linha_tempo"; then
        SUCESSO++
    else
        FALHAS++
        # Continua com prÃ³xima data
    fi
done
```

### GeraÃ§Ã£o Condicional do JSON

```bash
# JSON sÃ³ Ã© gerado se TODAS as datas tiveram sucesso
if [ $FALHAS -eq 0 ]; then
    gerar_json_dashboard()
else
    echo "âš ï¸  Snapshots processados com falhas, JSON nÃ£o gerado"
fi
```

## ğŸ“ˆ Indicadores DisponÃ­veis no Dashboard

### PrescriÃ§Ãµes e SuplementaÃ§Ã£o

| Indicador | Campo JSON | DescriÃ§Ã£o |
|-----------|-----------|-----------|
| Ãcido FÃ³lico | `perc_acido_folico` | % gestantes com prescriÃ§Ã£o de Ã¡cido fÃ³lico |
| Carbonato de CÃ¡lcio | `perc_carbonato_calcio` | % gestantes com prescriÃ§Ã£o de cÃ¡lcio |

### CondiÃ§Ãµes ClÃ­nicas

| Indicador | Campo JSON | DescriÃ§Ã£o |
|-----------|-----------|-----------|
| HipertensÃ£o | `perc_hipertensao` | % gestantes com diagnÃ³stico de hipertensÃ£o |
| Diabetes | `perc_diabetes` | % gestantes com diagnÃ³stico de diabetes |
| SÃ­filis | `perc_sifilis` | % gestantes com diagnÃ³stico de sÃ­filis |

### Controle de Tratamento

| Indicador | Campo JSON | DescriÃ§Ã£o |
|-----------|-----------|-----------|
| Hipertensas Medicadas | `perc_hipertensas_medicadas` | % hipertensas com medicaÃ§Ã£o segura |
| DiabÃ©ticas Medicadas | `perc_diabeticas_medicadas` | % diabÃ©ticas com antidiabÃ©tico |

### Dados Agregados

| Campo | DescriÃ§Ã£o |
|-------|-----------|
| `total_gestantes_ativas` | Total de gestaÃ§Ãµes ativas no snapshot |
| `gestantes_acido_folico` | Contagem absoluta com Ã¡cido fÃ³lico |
| `hipertensas_com_medicacao` | Contagem absoluta com anti-hipertensivos |

## âš ï¸ Troubleshooting

### Erro: "bq command not found"

```bash
# Instalar BigQuery CLI
gcloud components install bq

# Verificar instalaÃ§Ã£o
bq version
```

### Erro: "Not authenticated"

```bash
# Fazer login
gcloud auth login

# Configurar projeto
gcloud config set project rj-sms-sandbox

# Verificar autenticaÃ§Ã£o
bq ls --project_id=rj-sms-sandbox
```

### Erro: "Permission denied"

```bash
# Tornar script executÃ¡vel (apenas primeira vez)
chmod +x construir_historico.sh

# Verificar permissÃµes
ls -l construir_historico.sh
# Deve mostrar: -rwxr-xr-x
```

### Erro: "Table not found: _gestacoes_historico"

**Causa**: Tabelas histÃ³ricas nÃ£o foram criadas no BigQuery

**SoluÃ§Ã£o**:
```sql
-- Criar tabela _gestacoes_historico
CREATE TABLE IF NOT EXISTS `rj-sms-sandbox.sub_pav_us._gestacoes_historico` (
    data_snapshot DATE,
    id_hci STRING,
    id_gestacao STRING,
    id_paciente STRING,
    -- ... outros campos conforme schema
)
PARTITION BY data_snapshot
CLUSTER BY id_paciente, fase_atual;

-- Repetir para:
-- _atendimentos_prenatal_aps_historico
-- _linha_tempo_historico
```

### Script processa datas mas nÃ£o gera JSON

**Sintomas**: Mensagem "âš ï¸ Snapshots processados, mas houve erro ao gerar JSON do dashboard"

**Causas Comuns**:
1. Arquivo `query_dashboard_completo_clean.sql` nÃ£o encontrado
2. Erro na query do dashboard
3. PermissÃ£o de escrita no diretÃ³rio

**SoluÃ§Ãµes**:
```bash
# Verificar existÃªncia da query
ls -l ../query_dashboard_completo_clean.sql

# Gerar JSON manualmente
cd ..
bq query --format=json --use_legacy_sql=false < query_dashboard_completo_clean.sql > dashboard_data_completo.json

# Verificar permissÃµes de escrita
touch dashboard_data_completo.json
rm dashboard_data_completo.json
```

### Dashboard nÃ£o mostra todos os snapshots

**Sintomas**: JSON tem 3 snapshots mas dashboard mostra apenas 2

**Causa**: Cache do navegador

**SoluÃ§Ã£o**:
```bash
# Hard refresh no navegador
# Windows/Linux: Ctrl + Shift + R
# Mac: Cmd + Shift + R

# Se persistir, limpar cache completo
# Ctrl + Shift + Delete (ou Cmd + Shift + Delete)
# Marcar "Imagens e arquivos em cache"
```

### Performance muito lenta

**Sintomas**: Cada data leva > 5 minutos para processar

**Causas**:
- Volume grande de dados
- HorÃ¡rio de pico do BigQuery
- ConexÃ£o de rede lenta

**SoluÃ§Ãµes**:
```bash
# Processar em horÃ¡rios de baixo uso (madrugada, finais de semana)
# Reduzir nÃºmero de datas por execuÃ§Ã£o
# Verificar status do BigQuery: https://status.cloud.google.com/

# Monitorar jobs no BigQuery Console
# https://console.cloud.google.com/bigquery?project=rj-sms-sandbox
```

### Falha em data especÃ­fica

**Sintomas**: Algumas datas processam, outras falham

**Causa**: Dados inconsistentes ou faltantes naquela data

**SoluÃ§Ã£o**:
```bash
# Executar SQL manualmente para investigar
bq query --use_legacy_sql=false < _hist_1_gestacoes.sql

# Verificar logs de erro detalhados
# Procurar mensagens especÃ­ficas do BigQuery

# Remover data problemÃ¡tica da lista e reprocessar demais
```

## ğŸ¯ Boas PrÃ¡ticas

### âœ… RecomendaÃ§Ãµes

1. **Teste com 1 data primeiro**: Valide pipeline antes de processar sÃ©rie completa
   ```bash
   ./construir_historico.sh 2024-10-01  # Teste
   ```

2. **Use datas do Ãºltimo dia Ãºtil do perÃ­odo**: Para snapshots mensais
   ```bash
   # âœ… BOM: Ãšltimo dia do mÃªs
   ./construir_historico.sh 2024-01-31 2024-02-29
   ```

3. **Processe em horÃ¡rios de baixo uso**: Melhor performance
   - Madrugada: 00h-06h
   - Finais de semana

4. **Monitore o relatÃ³rio final**: Verifique sucessos/falhas
   ```bash
   ============================================================
   ğŸ“Š RELATÃ“RIO FINAL
   ============================================================
   âœ… Sucessos: 12
   âŒ Falhas: 0
   â±ï¸  Tempo total: 1847s
   ```

5. **Valide consistÃªncia**: Execute queries de verificaÃ§Ã£o
   ```sql
   -- Ver SQL de validaÃ§Ã£o na seÃ§Ã£o anterior
   ```

6. **Mantenha backups**: Antes de grandes reprocessamentos
   ```bash
   # Exportar tabela atual
   bq extract \
     rj-sms-sandbox:sub_pav_us._linha_tempo_historico \
     gs://seu-bucket/backup/linha_tempo_historico_$(date +%Y%m%d).json
   ```

### âŒ Evitar

1. **NÃ£o execute mÃºltiplas instÃ¢ncias simultaneamente**: Causa conflitos de INSERT
2. **NÃ£o misture datas aleatÃ³rias**: Prefira sÃ©ries contÃ­nuas para anÃ¡lise temporal
3. **NÃ£o ignore falhas**: Investigue e corrija antes de continuar
4. **NÃ£o processe em horÃ¡rios de pico**: Performance degradada
5. **NÃ£o execute manualmente cada SQL**: Use o script automatizado

## ğŸ” SeguranÃ§a e Compliance

### Dados Protegidos (LGPD/HIPAA)

âš ï¸ **ATENÃ‡ÃƒO**: Este pipeline processa dados de saÃºde protegidos (PHI)

**ObrigaÃ§Ãµes**:
- âœ… Acesso restrito a profissionais autorizados
- âœ… Logs de acesso habilitados
- âœ… Dados anonimizados em dashboards pÃºblicos
- âœ… RetenÃ§Ã£o conforme polÃ­ticas institucionais

**Boas prÃ¡ticas**:
```bash
# Nunca compartilhar credenciais
# Usar contas de serviÃ§o com permissÃµes mÃ­nimas
# Revisar periodicamente acessos
# Monitorar uso indevido
```

## ğŸ“Š Estrutura de Dados

### Tabelas HistÃ³ricas

Todas as tabelas usam este padrÃ£o:

```sql
CREATE TABLE `_[nome]_historico` (
    data_snapshot DATE,        -- â† Particionamento
    id_paciente STRING,        -- â† Clustering
    fase_atual STRING,         -- â† Clustering
    -- demais campos especÃ­ficos
)
PARTITION BY data_snapshot
CLUSTER BY id_paciente, fase_atual;
```

**BenefÃ­cios**:
- ğŸš€ Queries rÃ¡pidas com filtro por `data_snapshot`
- ğŸ’° Custo reduzido (scanning otimizado)
- ğŸ“¦ Dados organizados por data e paciente

### JSON do Dashboard

```json
[
  {
    "data_snapshot": "2024-10-01",
    "total_gestantes_ativas": 27312,
    "gestantes_acido_folico": 17614,
    "perc_acido_folico": 64.49,
    "gestantes_hipertensao": 1069,
    "perc_hipertensao": 3.91,
    // ... outros indicadores
  },
  // ... outros snapshots
]
```

## ğŸš€ IntegraÃ§Ã£o com Dashboard

### Fluxo Completo

```
1. Executar script â†’ processa datas â†’ INSERT BigQuery
                                           â†“
2. Query dashboard â†’ agrega indicadores â†’ JSON
                                           â†“
3. Navegador â†’ carrega JSON â†’ renderiza grÃ¡ficos
```

### AtualizaÃ§Ã£o AutomÃ¡tica

ApÃ³s executar o script:

```bash
# Script jÃ¡ fez:
# âœ… Processou todas as datas
# âœ… Gerou dashboard_data_completo.json
# âœ… Dashboard automaticamente carrega novos dados

# VocÃª sÃ³ precisa:
# 1. Hard refresh no navegador (Ctrl+Shift+R)
# 2. Navegar pelas datas no calendÃ¡rio
```

### CustomizaÃ§Ã£o do Dashboard

Para adicionar novos indicadores:

1. **Editar query do dashboard**: `../query_dashboard_completo_clean.sql`
   ```sql
   -- Adicionar nova coluna
   COUNTIF(condicao_nova = 1) AS novo_indicador,
   ```

2. **Reprocessar JSON**: Script faz automaticamente
   ```bash
   ./construir_historico.sh 2024-10-01
   ```

3. **Atualizar HTML do dashboard**: `../dashboard_prescricoes_v2.html`
   ```javascript
   // Adicionar na funÃ§Ã£o processCompleteData()
   novo_indicador: parseInt(row.novo_indicador || 0)
   ```

## ğŸ“š ReferÃªncias

### DocumentaÃ§Ã£o Relacionada

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `../README_HISTORICO_COMPLETO.md` | Sistema completo de procedimentos histÃ³ricos |
| `../CLAUDE.md` | Conceitos de negÃ³cio e lÃ³gica clÃ­nica |
| `README_CONSTRUIR_HISTORICO.md` | Guia detalhado do script bash |
| `exemplo_uso.sh` | Exemplos prÃ¡ticos de execuÃ§Ã£o |

### DocumentaÃ§Ã£o TÃ©cnica

- **BigQuery CLI**: https://cloud.google.com/bigquery/docs/bq-command-line-tool
- **SQL Parametrizado**: https://cloud.google.com/bigquery/docs/parameterized-queries
- **Bash Scripting**: https://www.gnu.org/software/bash/manual/

### ReferÃªncias ClÃ­nicas

- **PrÃ©-Natal**: MinistÃ©rio da SaÃºde - Cadernos de AtenÃ§Ã£o BÃ¡sica nÂº 32
- **CID-10**: CapÃ­tulo XV (O00-O99) - Gravidez, parto e puerpÃ©rio
- **ICD ObstÃ©trico**: Z32.1, Z34%, Z35% (gestaÃ§Ã£o confirmada, supervisÃ£o)

## ğŸ¯ Roadmap

### PrÃ³ximas Melhorias

- [ ] Adicionar flag `--parallel` para processar datas em paralelo
- [ ] Implementar retry automÃ¡tico para falhas temporÃ¡rias
- [ ] Adicionar exportaÃ§Ã£o para CSV alÃ©m de JSON
- [ ] Criar dashboards especÃ­ficos por indicador (HAS, DM, etc.)
- [ ] Implementar versionamento de schemas
- [ ] Adicionar testes automatizados de consistÃªncia
- [ ] Criar notificaÃ§Ãµes por email em caso de falha
- [ ] Adicionar suporte para processar apenas tabelas especÃ­ficas

### Melhorias no Dashboard

- [ ] Filtros por regiÃ£o/clÃ­nica
- [ ] ComparaÃ§Ã£o de perÃ­odos lado a lado
- [ ] ExportaÃ§Ã£o de grÃ¡ficos como imagem
- [ ] Alertas visuais para indicadores crÃ­ticos
- [ ] PrevisÃ£o de tendÃªncias (machine learning)

## ğŸ’¬ Suporte

Para questÃµes sobre:
- **Uso do script**: Consulte `README_CONSTRUIR_HISTORICO.md`
- **LÃ³gica de negÃ³cio**: Consulte `../README_HISTORICO_COMPLETO.md`
- **Performance**: Verifique plano de execuÃ§Ã£o no BigQuery Console
- **Erros**: Consulte seÃ§Ã£o de Troubleshooting acima

## ğŸ“ LicenÃ§a

Este projeto faz parte do sistema de informaÃ§Ã£o em saÃºde da Secretaria Municipal de SaÃºde do Rio de Janeiro.

**Uso restrito**: Dados protegidos por LGPD (Lei Geral de ProteÃ§Ã£o de Dados).

---

**Ãšltima atualizaÃ§Ã£o**: Dezembro 2024
**VersÃ£o**: 2.0 - Pipeline automatizado com geraÃ§Ã£o de JSON do dashboard
